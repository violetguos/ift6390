{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Practical part: Density estimation\n",
    "\n",
    "IFT 6390 Fall/Automne 2018, HW1, Q4, practical\n",
    "\n",
    "Arlie Coles (20121051) & Violet Guo ()\n",
    "\n",
    "*Note to TAs: these implementations run on Python 3.*\n",
    "\n",
    "## 1. Implementation of a Gaussian parametric density estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training mean is: 2.33333333333\n",
      "The training covariance matrix is: \n",
      " [[ 0.03703704  0.          0.        ]\n",
      " [ 0.          0.03703704  0.        ]\n",
      " [ 0.          0.          0.14814815]]\n",
      "('np.diag(self.train_cov)', array([ 0.03703704,  0.03703704,  0.14814815]))\n",
      "('train_cov_inv', array([[ 27.  ,   0.  ,   0.  ],\n",
      "       [  0.  ,  27.  ,   0.  ],\n",
      "       [  0.  ,   0.  ,   6.75]]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class gaussianDiag:\n",
    "    def __init__(self, data, label):\n",
    "        self.train_data = data\n",
    "        self.train_label = label\n",
    "        self.train_mean = 0\n",
    "        self.train_cov = 0\n",
    "    \n",
    "    def train_diag(self):\n",
    "        '''\n",
    "        Calculate the mean and generate a diagonal covariance matrix\n",
    "        '''\n",
    "        d = self.train_data.shape\n",
    "        # print(d)\n",
    "        self.train_mean = np.mean(self.train_data)\n",
    "        print(\"The training mean is: {}\".format(self.train_mean))\n",
    "        self.train_cov = np.multiply( \n",
    "            (self.train_data - self.train_mean), np.transpose((self.train_data - self.train_mean))\n",
    "        )\n",
    "        self.train_cov =np.diag(self.train_cov /d)\n",
    "        print(\"The training covariance matrix is: \\n {}\".format(self.train_cov))\n",
    "        \n",
    "        return self.train_mean, self.train_cov\n",
    "\n",
    "\n",
    "    def predict_diag(self, train_label):\n",
    "        # I'm not too sure what's going on here - Arlie\n",
    "        '''\n",
    "        Calculate the log density\n",
    "        '''\n",
    "    \n",
    "        # Take the inverse of diagonals cov\n",
    "        print(\"np.diag(self.train_cov)\", np.diag(self.train_cov))\n",
    "        train_cov_inv = np.linalg.inv(self.train_cov)\n",
    "        print(\"train_cov_inv\", train_cov_inv)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "data = np.array([2 ,2,3])\n",
    "label = np.array([3,2,2])\n",
    "part1 = gaussianDiag(data, label)\n",
    "\n",
    "part1.train_diag()\n",
    "part1.predict_diag(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2:  Implementation of a Parzen density estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class parzenEstimator:\n",
    "    def __init__(self, data, kernel_stdev):\n",
    "        self.train_data = data\n",
    "        self.kernel_stdev = kernel_stdev\n",
    "        self.d = len(self.train_data.T) # Get dimension; shape method too finicky returning \"L\" for long int type\n",
    "\n",
    "    def train(self, train_data):\n",
    "        # Loading datapoints was taken care of in the constructor above.\n",
    "        # This function creates the lambda function that makes summing easier/faster in the predict() function.\n",
    "        # This metaphorically \"creates\" a Gaussian centered on each datapoint, while leaving the slot in the pdf for\n",
    "        #  the test point open, until the weighting actually occurs at test time.\n",
    "        norm_const = 1/np.multiply((2*math.pi)**(self.d/2), self.kernel_stdev**self.d)\n",
    "        self.summand = lambda x, mu : np.multiply(norm_const, np.exp(np.multiply(-0.5, ((np.absolute(x - mu))/(self.kernel_stdev**2)))))\n",
    "\n",
    "    def predict(self, test_point):\n",
    "        # Sum over the kernels with the datapoint as x\n",
    "        density = 0\n",
    "        for datapoint in self.train_data:\n",
    "            density += self.summand(test_point, datapoint)\n",
    "        log_density = np.log(density)\n",
    "        return log_density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the Parzen estimator with some dummy data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.06528834  0.93471166  0.36849249]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[2 ,2,3], [2,2,2]])\n",
    "test_point = np.array([1,2,3])\n",
    "\n",
    "part2 = parzenEstimator(data, 0.5)\n",
    "part2.train(data)\n",
    "print(part2.predict(test_point))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 1D densities\n",
    "\n",
    "First, let's open and parse the Iris dataset, selecting just the versicolor class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('iris.data', 'r') as fp:\n",
    "    iris_data = fp.readlines()\n",
    "\n",
    "# Get just the versicolor class\n",
    "versicolor_lines = []\n",
    "for line in iris_data:\n",
    "    if 'versicolor' in line:\n",
    "        versicolor_lines.append(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's further select just the data for sepal length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1d = []\n",
    "for line in versicolor_lines:\n",
    "    data_1d.append(line.split(',')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a)\n",
    "\n",
    "A plot of the data points of the subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7.0', '6.4', '6.9', '5.5', '6.5', '5.7', '6.3', '4.9', '6.6', '5.2', '5.0', '5.9', '6.0', '6.1', '5.6', '6.7', '5.6', '5.8', '6.2', '5.6', '5.9', '6.1', '6.3', '6.1', '6.4', '6.6', '6.8', '6.7', '6.0', '5.7', '5.5', '5.5', '5.8', '6.0', '5.4', '6.0', '6.7', '6.3', '5.6', '5.5', '5.5', '6.1', '5.8', '5.0', '5.6', '5.7', '5.7', '6.2', '5.1', '5.7']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "xlabel() takes at least 1 argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-b13548292860>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_1d\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_1d\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: xlabel() takes at least 1 argument (0 given)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(data_1d)\n",
    "plt.plot(data_1d)\n",
    "plt.xlabel()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
