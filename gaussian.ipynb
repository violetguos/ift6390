{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Practical part: Density estimation\n",
    "\n",
    "IFT 6390 Fall/Automne 2018, HW1, Q4, practical\n",
    "\n",
    "Arlie Coles (20121051) & Violet Guo ()\n",
    "\n",
    "*Note to TAs: these implementations run on Python 3.*\n",
    "\n",
    "## 1. Implementation of a Gaussian parametric density estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training mean is: 2.33333333333\n",
      "The training covariance matrix is: \n",
      " [[ 0.03703704  0.          0.        ]\n",
      " [ 0.          0.03703704  0.        ]\n",
      " [ 0.          0.          0.14814815]]\n",
      "('np.diag(self.train_cov)', array([ 0.03703704,  0.03703704,  0.14814815]))\n",
      "('train_cov_inv', array([[ 27.  ,   0.  ,   0.  ],\n",
      "       [  0.  ,  27.  ,   0.  ],\n",
      "       [  0.  ,   0.  ,   6.75]]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class gaussianDiag:\n",
    "    def __init__(self, data, label):\n",
    "        self.train_data = data\n",
    "        self.train_label = label\n",
    "        self.train_mean = 0\n",
    "        self.train_cov = 0\n",
    "    \n",
    "    def train_diag(self):\n",
    "        '''\n",
    "        Calculate the mean and generate a diagonal covariance matrix\n",
    "        '''\n",
    "        d = self.train_data.shape\n",
    "        # print(d)\n",
    "        self.train_mean = np.mean(self.train_data)\n",
    "        print(\"The training mean is: {}\".format(self.train_mean))\n",
    "        self.train_cov = np.multiply( \n",
    "            (self.train_data - self.train_mean), np.transpose((self.train_data - self.train_mean))\n",
    "        )\n",
    "        self.train_cov =np.diag(self.train_cov /d)\n",
    "        print(\"The training covariance matrix is: \\n {}\".format(self.train_cov))\n",
    "        \n",
    "        return self.train_mean, self.train_cov\n",
    "\n",
    "\n",
    "    def predict_diag(self, train_label):\n",
    "        # I'm not too sure what's going on here - Arlie\n",
    "        '''\n",
    "        Calculate the log density\n",
    "        '''\n",
    "    \n",
    "        # Take the inverse of diagonals cov\n",
    "        print(\"np.diag(self.train_cov)\", np.diag(self.train_cov))\n",
    "        train_cov_inv = np.linalg.inv(self.train_cov)\n",
    "        print(\"train_cov_inv\", train_cov_inv)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "data = np.array([2 ,2,3])\n",
    "label = np.array([3,2,2])\n",
    "part1 = gaussianDiag(data, label)\n",
    "\n",
    "part1.train_diag()\n",
    "part1.predict_diag(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2:  Implementation of a Parzen density estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class parzenEstimator:\n",
    "    def __init__(self, data, kernel_stdev):\n",
    "        self.train_data = data\n",
    "        self.kernel_stdev = kernel_stdev\n",
    "        self.d = len(self.train_data.T) # Get dimension; shape method too finicky returning \"L\" for long int type\n",
    "\n",
    "    def train(self, train_data):\n",
    "        # Loading datapoints was taken care of in the constructor above.\n",
    "        # This function creates the lambda function that makes summing easier/faster in the predict() function.\n",
    "        # This metaphorically \"creates\" a Gaussian centered on each datapoint, while leaving the slot in the pdf for\n",
    "        #  the test point open, until the weighting actually occurs at test time.\n",
    "        norm_const = 1/np.multiply((2*math.pi)**(self.d/2), self.kernel_stdev**self.d)\n",
    "        self.summand = lambda x, mu : np.multiply(norm_const, np.exp(np.multiply(-0.5, ((np.absolute(x - mu))/(self.kernel_stdev**2)))))\n",
    "\n",
    "    def predict(self, test_point):\n",
    "        # Sum over the kernels with the datapoint as x\n",
    "        density = 0\n",
    "        for datapoint in self.train_data:\n",
    "            density += self.summand(test_point, datapoint)\n",
    "        log_density = np.log(density)\n",
    "        return log_density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the Parzen estimator with some dummy data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.06528834  0.93471166  0.36849249]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[2 ,2,3], [2,2,2]])\n",
    "test_point = np.array([1,2,3])\n",
    "\n",
    "part2 = parzenEstimator(data, 0.5)\n",
    "part2.train(data)\n",
    "print(part2.predict(test_point))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 1D densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
