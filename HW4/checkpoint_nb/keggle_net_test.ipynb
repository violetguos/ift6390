{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keggle_net_test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "BecJFKDDBtcl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s9nL14i0G4NF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import data from Google drive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_jMT2ARgG7tA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# software, math libraries\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P902w4TOG9a5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tz2760cNJMdi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 2. Import data from google drive (id is from google drive shareable link)\n",
        "\n",
        "# Get training data\n",
        "download = drive.CreateFile({'id': '1BEp0SzrCinaDP3Icb8PkTQge5c1ymS94'})\n",
        "download.GetContentFile('train_images.npy')\n",
        "download = drive.CreateFile({'id': '1pKyWJtNEu3O1XukE75iOHteLHRVCDjPG'})\n",
        "download.GetContentFile('train_labels.csv')\n",
        "\n",
        "# Get test data\n",
        "download = drive.CreateFile({'id': '1BEp0SzrCinaDP3Icb8PkTQge5c1ymS94'})\n",
        "download.GetContentFile('test_images.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3fwmSRjUIo-4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "84908356-e5d9-4aa3-9d5f-3f6358179d75"
      },
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls ../.."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "bin\t    content  etc   lib64  opt\trun   sys    usr\n",
            "boot\t    datalab  home  media  proc\tsbin  tmp    var\n",
            "colabtools  dev      lib   mnt\t  root\tsrv   tools\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KuSwsOD3HHEN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#! CHANGE THIS!!\n",
        "\n",
        "images_train = np.load('./train_images.npy', encoding='latin1')\n",
        "train_labels = pd.read_csv('./train_labels.csv')\n",
        "\n",
        "label_list = train_labels.Category.unique().tolist()\n",
        "label_dict = {label:i  for i,label in enumerate(label_list)}\n",
        "train_labels['Category_num'] = train_labels.Category.apply(lambda x: label_dict[x])\n",
        "\n",
        "train_df = pd.DataFrame(images_train, columns = ['Id', 'img'])\n",
        "train_df = pd.merge(train_df, train_labels, on = 'Id')\n",
        "\n",
        "images_test = np.load('./test_images.npy', encoding='latin1')\n",
        "test_df = pd.DataFrame(images_test, columns = ['Id', 'img'])\n",
        "\n",
        "#print(train_df.head(n=5))\n",
        "\n",
        "training_vectors = np.array(train_df['img'].tolist())\n",
        "\n",
        "# Split into training and validation\n",
        "validation_vectors = training_vectors[9000:]\n",
        "validation_labels = train_labels['Category_num'][9000:]\n",
        "training_vectors = training_vectors[:9000]\n",
        "training_labels = train_labels['Category_num'][:9000]\n",
        "\n",
        "testing_vectors = np.array(test_df['img'].tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V0KlHVCYHDMp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2b4ea617-8f56-4eb4-a833-f4d425c9181d"
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "#one-hot encode target column\n",
        "train_targets = to_categorical(training_labels)\n",
        "validation_targets = to_categorical(validation_labels)\n",
        "train_targets[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "8U5PH2dQHUI4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8cb38da0-62b9-4779-867c-2f9ba4742891"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "DATA_PATH = \"/content/drive/My Drive/kaggle_hw4\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rZa94_P4HWWV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff504037-8053-43e1-e37c-aed546ea07a1"
      },
      "cell_type": "code",
      "source": [
        "# RUN THIS TO LOAD THE PICKLE!\n",
        "import os\n",
        "DATA_PATH = \"/content/drive/My Drive/kaggle_hw4\"\n",
        "with open(os.path.join(DATA_PATH, 'train_data_preproc.pickle'), 'rb') as jar:\n",
        "  train_data = pickle.load(jar)\n",
        "  \n",
        "with open(os.path.join(DATA_PATH, 'valid_data_preproc.pickle'), 'rb') as jar:\n",
        "  valid_data = pickle.load(jar)\n",
        "\n",
        "print(len(train_data))\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cxBuYwkKHdgn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "outputId": "ea9c0da4-679f-4384-94fb-80be77836d91"
      },
      "cell_type": "code",
      "source": [
        "# try plotting the pickled\n",
        "\n",
        "\n",
        "\n",
        "train_data = np.array(train_data)\n",
        "print(train_data.shape)\n",
        "\n",
        "print(train_data.shape)\n",
        "\n",
        "\n",
        "\n",
        "valid_data = np.array(valid_data)\n",
        "print(valid_data.shape)\n",
        "\n",
        "print(valid_data.shape)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(train_data[0].reshape(100, 100))\n",
        "plt.figure()\n",
        "plt.imshow(valid_data[0].reshape(100, 100))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9000, 100, 100)\n",
            "(9000, 100, 100)\n",
            "(1000, 100, 100)\n",
            "(1000, 100, 100)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbbfd1819e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD7CAYAAABDsImYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMOhSAQZdKsCgSwX8P5Z3Di8v8XFJAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbc3bae4358>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD7CAYAAABDsImYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMOhSAgZdSsCgSwn8P7kMPG0Bb93GAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbbfd192518>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Izr0ocQFHi8N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8248c335-dd4c-4009-a557-b1cbccaa5663"
      },
      "cell_type": "code",
      "source": [
        "# reshape to n by 100 by 100 by 3 for VGG\n",
        "#train_data = train_data.reshape(train_data.shape + (1,))\n",
        "#valid_data = valid_data.reshape(valid_data.shape + (1,))\n",
        "\n",
        "\n",
        "vgg_train_data = np.stack((train_data,train_data,train_data), axis = -1)\n",
        "print(vgg_train_data.shape)\n",
        "#vgg_train_data= vgg_train_data.reshape(9000, 100, 100, 3)\n",
        "print(vgg_train_data.shape)\n",
        "\n",
        "\n",
        "vgg_validation_data = np.stack((valid_data, valid_data, valid_data), axis = -1)\n",
        "#vgg_validation_data = vgg_validation_data.reshape(1000, 100, 100, 3)\n",
        "print(vgg_validation_data.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9000, 100, 100, 3)\n",
            "(9000, 100, 100, 3)\n",
            "(1000, 100, 100, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SFD0jQe6MDwA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.layers import Input, Flatten, Dense\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "\n",
        "def create_model():\n",
        "\n",
        "  #Get back the convolutional part of a VGG network trained on ImageNet\n",
        "  model_vgg16_conv = VGG16(weights='imagenet', include_top=False)\n",
        "  model_vgg16_conv.summary()\n",
        "\n",
        "  #Create your own input format (here 3x100x100)\n",
        "  input = Input(shape=(100,100, 3),name = 'image_input')\n",
        "\n",
        "  #Use the generated model \n",
        "  output_vgg16_conv = model_vgg16_conv(input)\n",
        "\n",
        "  #Add the fully-connected layers \n",
        "  x = Flatten(name='flatten')(output_vgg16_conv)\n",
        "  x = Dense(4096, activation='relu', name='fc1')(x)\n",
        "  x = Dense(4096, activation='relu', name='fc2')(x)\n",
        "  x = Dense(31, activation='softmax', name='predictions')(x)\n",
        "\n",
        "  #Create your own model \n",
        "  my_model = Model(input=input, output=x)\n",
        "\n",
        "  #In the summary, weights and layers from VGG part will be hidden, but they will be fit during the training\n",
        "  my_model.summary()\n",
        "\n",
        "\n",
        "  sgd = SGD(lr=0.0005, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "  my_model.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  return my_model\n",
        "\n",
        "\n",
        "#Then training with your data ! \n",
        "#my_model.fit(x=vgg_train_data, y=train_targets, batch_size=100, epochs=20, \n",
        "#             verbose=1, callbacks=None, validation_split=0.1,\n",
        "#             validation_data=None,\n",
        "#             shuffle=True, class_weight=None, sample_weight=None, \n",
        "#             initial_epoch=0, steps_per_epoch=None, validation_steps=None)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kfu9iSkcHzLO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4899
        },
        "outputId": "beb5c3ed-ccbe-460e-95e7-c2a6651b8bd5"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "model = None\n",
        "model = create_model()\n",
        "kfold_splits = 10\n",
        "skf = StratifiedKFold(n_splits=kfold_splits, shuffle=True, random_state = 1)\n",
        "\n",
        "\n",
        "print(\"training_labels\", training_labels.shape)\n",
        "\n",
        "# MUST use training_labels, one num to indiate category\n",
        "# one hot incode in the fit itself\n",
        "for index, (train_indices, val_indices) in enumerate(skf.split(vgg_train_data, training_labels)):\n",
        "  print(\"Training on fold \" + str(index+1) + \"/10...\")\n",
        "  # Generate batches from indices\n",
        "  xtrain, xval = vgg_train_data[train_indices], vgg_train_data[val_indices]\n",
        "  ytrain, yval = training_labels[train_indices], training_labels[val_indices]\n",
        "  \n",
        "  ytrain = to_categorical(ytrain)\n",
        "  yval = to_categorical(yval)\n",
        "  \n",
        "  model.fit(xtrain, ytrain, validation_data=(xval, yval), batch_size=100, epochs=10)\n",
        "\n",
        "    \n",
        "  "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "image_input (InputLayer)     (None, 100, 100, 3)       0         \n",
            "_________________________________________________________________\n",
            "vgg16 (Model)                multiple                  14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              18878464  \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 31)                127007    \n",
            "=================================================================\n",
            "Total params: 50,501,471\n",
            "Trainable params: 50,501,471\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "training_labels (9000,)\n",
            "Training on fold 1/10...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"im..., outputs=Tensor(\"pr...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 8084 samples, validate on 916 samples\n",
            "Epoch 1/10\n",
            "8084/8084 [==============================] - 55s 7ms/step - loss: 3.1041 - acc: 0.1676 - val_loss: 2.4589 - val_acc: 0.3090\n",
            "Epoch 2/10\n",
            "8084/8084 [==============================] - 54s 7ms/step - loss: 1.9993 - acc: 0.4254 - val_loss: 1.7955 - val_acc: 0.4880\n",
            "Epoch 3/10\n",
            "8084/8084 [==============================] - 54s 7ms/step - loss: 1.5780 - acc: 0.5464 - val_loss: 1.5752 - val_acc: 0.5546\n",
            "Epoch 4/10\n",
            "8084/8084 [==============================] - 54s 7ms/step - loss: 1.3795 - acc: 0.6003 - val_loss: 1.5388 - val_acc: 0.5808\n",
            "Epoch 5/10\n",
            "8084/8084 [==============================] - 54s 7ms/step - loss: 1.2401 - acc: 0.6414 - val_loss: 1.4253 - val_acc: 0.5873\n",
            "Epoch 6/10\n",
            "8084/8084 [==============================] - 54s 7ms/step - loss: 1.1412 - acc: 0.6697 - val_loss: 1.3667 - val_acc: 0.6157\n",
            "Epoch 7/10\n",
            "8084/8084 [==============================] - 54s 7ms/step - loss: 1.0470 - acc: 0.6914 - val_loss: 1.3328 - val_acc: 0.6310\n",
            "Epoch 8/10\n",
            "8084/8084 [==============================] - 54s 7ms/step - loss: 0.9626 - acc: 0.7138 - val_loss: 1.4501 - val_acc: 0.5884\n",
            "Epoch 9/10\n",
            "8084/8084 [==============================] - 54s 7ms/step - loss: 0.8790 - acc: 0.7420 - val_loss: 1.3287 - val_acc: 0.6332\n",
            "Epoch 10/10\n",
            "8084/8084 [==============================] - 54s 7ms/step - loss: 0.8061 - acc: 0.7598 - val_loss: 1.4458 - val_acc: 0.6255\n",
            "Training on fold 2/10...\n",
            "Train on 8090 samples, validate on 910 samples\n",
            "Epoch 1/10\n",
            "8090/8090 [==============================] - 54s 7ms/step - loss: 0.8410 - acc: 0.7557 - val_loss: 0.8206 - val_acc: 0.7505\n",
            "Epoch 2/10\n",
            "8090/8090 [==============================] - 54s 7ms/step - loss: 0.7420 - acc: 0.7792 - val_loss: 0.8568 - val_acc: 0.7407\n",
            "Epoch 3/10\n",
            "8090/8090 [==============================] - 54s 7ms/step - loss: 0.6927 - acc: 0.7930 - val_loss: 0.8592 - val_acc: 0.7473\n",
            "Epoch 4/10\n",
            "8090/8090 [==============================] - 54s 7ms/step - loss: 0.6368 - acc: 0.8073 - val_loss: 0.9422 - val_acc: 0.7330\n",
            "Epoch 5/10\n",
            "8090/8090 [==============================] - 54s 7ms/step - loss: 0.5927 - acc: 0.8236 - val_loss: 0.9053 - val_acc: 0.7286\n",
            "Epoch 6/10\n",
            "8090/8090 [==============================] - 54s 7ms/step - loss: 0.5373 - acc: 0.8389 - val_loss: 0.9039 - val_acc: 0.7484\n",
            "Epoch 7/10\n",
            "8090/8090 [==============================] - 54s 7ms/step - loss: 0.4840 - acc: 0.8564 - val_loss: 0.9356 - val_acc: 0.7440\n",
            "Epoch 8/10\n",
            "8090/8090 [==============================] - 54s 7ms/step - loss: 0.4773 - acc: 0.8555 - val_loss: 1.0627 - val_acc: 0.7154\n",
            "Epoch 9/10\n",
            "8090/8090 [==============================] - 54s 7ms/step - loss: 0.4888 - acc: 0.8497 - val_loss: 1.0656 - val_acc: 0.7297\n",
            "Epoch 10/10\n",
            "8090/8090 [==============================] - 54s 7ms/step - loss: 0.4410 - acc: 0.8655 - val_loss: 1.0811 - val_acc: 0.7396\n",
            "Training on fold 3/10...\n",
            "Train on 8092 samples, validate on 908 samples\n",
            "Epoch 1/10\n",
            "8092/8092 [==============================] - 54s 7ms/step - loss: 0.5243 - acc: 0.8469 - val_loss: 0.4207 - val_acc: 0.8744\n",
            "Epoch 2/10\n",
            "8092/8092 [==============================] - 54s 7ms/step - loss: 0.4392 - acc: 0.8688 - val_loss: 0.4573 - val_acc: 0.8601\n",
            "Epoch 3/10\n",
            "8092/8092 [==============================] - 54s 7ms/step - loss: 0.4133 - acc: 0.8752 - val_loss: 0.4471 - val_acc: 0.8678\n",
            "Epoch 4/10\n",
            "8092/8092 [==============================] - 54s 7ms/step - loss: 0.3822 - acc: 0.8820 - val_loss: 0.4226 - val_acc: 0.8667\n",
            "Epoch 5/10\n",
            "8092/8092 [==============================] - 54s 7ms/step - loss: 0.3852 - acc: 0.8809 - val_loss: 0.5302 - val_acc: 0.8436\n",
            "Epoch 6/10\n",
            "8092/8092 [==============================] - 54s 7ms/step - loss: 0.3740 - acc: 0.8900 - val_loss: 0.8949 - val_acc: 0.7390\n",
            "Epoch 7/10\n",
            "8092/8092 [==============================] - 54s 7ms/step - loss: 0.3471 - acc: 0.8938 - val_loss: 0.4957 - val_acc: 0.8447\n",
            "Epoch 8/10\n",
            "8092/8092 [==============================] - 54s 7ms/step - loss: 0.2900 - acc: 0.9125 - val_loss: 0.5535 - val_acc: 0.8502\n",
            "Epoch 9/10\n",
            "8092/8092 [==============================] - 54s 7ms/step - loss: 0.2969 - acc: 0.9107 - val_loss: 0.6454 - val_acc: 0.8073\n",
            "Epoch 10/10\n",
            "8092/8092 [==============================] - 54s 7ms/step - loss: 0.2844 - acc: 0.9130 - val_loss: 0.6158 - val_acc: 0.8249\n",
            "Training on fold 4/10...\n",
            "Train on 8095 samples, validate on 905 samples\n",
            "Epoch 1/10\n",
            "8095/8095 [==============================] - 54s 7ms/step - loss: 0.3461 - acc: 0.8919 - val_loss: 0.2225 - val_acc: 0.9381\n",
            "Epoch 2/10\n",
            "8095/8095 [==============================] - 54s 7ms/step - loss: 0.3021 - acc: 0.9090 - val_loss: 0.2574 - val_acc: 0.9204\n",
            "Epoch 3/10\n",
            "8095/8095 [==============================] - 54s 7ms/step - loss: 0.2525 - acc: 0.9238 - val_loss: 0.2837 - val_acc: 0.9083\n",
            "Epoch 4/10\n",
            "8095/8095 [==============================] - 54s 7ms/step - loss: 0.2297 - acc: 0.9295 - val_loss: 0.3405 - val_acc: 0.8939\n",
            "Epoch 5/10\n",
            "8095/8095 [==============================] - 54s 7ms/step - loss: 0.2250 - acc: 0.9319 - val_loss: 0.2933 - val_acc: 0.9204\n",
            "Epoch 6/10\n",
            "8095/8095 [==============================] - 54s 7ms/step - loss: 0.1871 - acc: 0.9437 - val_loss: 0.3298 - val_acc: 0.8884\n",
            "Epoch 7/10\n",
            "8095/8095 [==============================] - 54s 7ms/step - loss: 0.1780 - acc: 0.9465 - val_loss: 0.4226 - val_acc: 0.8796\n",
            "Epoch 8/10\n",
            "8095/8095 [==============================] - 54s 7ms/step - loss: 0.1587 - acc: 0.9508 - val_loss: 0.3357 - val_acc: 0.8961\n",
            "Epoch 9/10\n",
            "8095/8095 [==============================] - 54s 7ms/step - loss: 0.1445 - acc: 0.9574 - val_loss: 0.3696 - val_acc: 0.8928\n",
            "Epoch 10/10\n",
            "8095/8095 [==============================] - 54s 7ms/step - loss: 0.1188 - acc: 0.9642 - val_loss: 0.4828 - val_acc: 0.8541\n",
            "Training on fold 5/10...\n",
            "Train on 8099 samples, validate on 901 samples\n",
            "Epoch 1/10\n",
            "8099/8099 [==============================] - 54s 7ms/step - loss: 0.2053 - acc: 0.9388 - val_loss: 0.1654 - val_acc: 0.9567\n",
            "Epoch 2/10\n",
            "8099/8099 [==============================] - 54s 7ms/step - loss: 0.1351 - acc: 0.9580 - val_loss: 0.1873 - val_acc: 0.9456\n",
            "Epoch 3/10\n",
            "8099/8099 [==============================] - 54s 7ms/step - loss: 0.1157 - acc: 0.9653 - val_loss: 0.1521 - val_acc: 0.9489\n",
            "Epoch 4/10\n",
            "8099/8099 [==============================] - 54s 7ms/step - loss: 0.1224 - acc: 0.9639 - val_loss: 0.1593 - val_acc: 0.9456\n",
            "Epoch 5/10\n",
            "8099/8099 [==============================] - 54s 7ms/step - loss: 0.0826 - acc: 0.9763 - val_loss: 0.2929 - val_acc: 0.8979\n",
            "Epoch 6/10\n",
            "8099/8099 [==============================] - 54s 7ms/step - loss: 0.0879 - acc: 0.9749 - val_loss: 0.2052 - val_acc: 0.9412\n",
            "Epoch 7/10\n",
            "8099/8099 [==============================] - 54s 7ms/step - loss: 0.0798 - acc: 0.9758 - val_loss: 0.2149 - val_acc: 0.9345\n",
            "Epoch 8/10\n",
            "8099/8099 [==============================] - 54s 7ms/step - loss: 0.0538 - acc: 0.9862 - val_loss: 0.1917 - val_acc: 0.9367\n",
            "Epoch 9/10\n",
            "8099/8099 [==============================] - 54s 7ms/step - loss: 0.0212 - acc: 0.9946 - val_loss: 0.1502 - val_acc: 0.9501\n",
            "Epoch 10/10\n",
            "8099/8099 [==============================] - 54s 7ms/step - loss: 0.0187 - acc: 0.9957 - val_loss: 0.1982 - val_acc: 0.9378\n",
            "Training on fold 6/10...\n",
            "Train on 8104 samples, validate on 896 samples\n",
            "Epoch 1/10\n",
            "8104/8104 [==============================] - 54s 7ms/step - loss: 0.0627 - acc: 0.9819 - val_loss: 0.1199 - val_acc: 0.9609\n",
            "Epoch 2/10\n",
            "8104/8104 [==============================] - 54s 7ms/step - loss: 0.0665 - acc: 0.9804 - val_loss: 0.1063 - val_acc: 0.9643\n",
            "Epoch 3/10\n",
            "8104/8104 [==============================] - 54s 7ms/step - loss: 0.0733 - acc: 0.9793 - val_loss: 0.1134 - val_acc: 0.9632\n",
            "Epoch 4/10\n",
            "8104/8104 [==============================] - 54s 7ms/step - loss: 0.0499 - acc: 0.9832 - val_loss: 1.6799 - val_acc: 0.7835\n",
            "Epoch 5/10\n",
            "8104/8104 [==============================] - 54s 7ms/step - loss: 0.3665 - acc: 0.9005 - val_loss: 0.7248 - val_acc: 0.8605\n",
            "Epoch 6/10\n",
            "8104/8104 [==============================] - 54s 7ms/step - loss: 0.1915 - acc: 0.9409 - val_loss: 0.2511 - val_acc: 0.9118\n",
            "Epoch 7/10\n",
            "8104/8104 [==============================] - 54s 7ms/step - loss: 0.0753 - acc: 0.9796 - val_loss: 0.2520 - val_acc: 0.9241\n",
            "Epoch 8/10\n",
            "8104/8104 [==============================] - 54s 7ms/step - loss: 0.1041 - acc: 0.9661 - val_loss: 0.2211 - val_acc: 0.9196\n",
            "Epoch 9/10\n",
            "8104/8104 [==============================] - 54s 7ms/step - loss: 0.0557 - acc: 0.9858 - val_loss: 0.1771 - val_acc: 0.9542\n",
            "Epoch 10/10\n",
            "8104/8104 [==============================] - 54s 7ms/step - loss: 0.0347 - acc: 0.9914 - val_loss: 0.2018 - val_acc: 0.9364\n",
            "Training on fold 7/10...\n",
            "Train on 8105 samples, validate on 895 samples\n",
            "Epoch 1/10\n",
            "8105/8105 [==============================] - 54s 7ms/step - loss: 0.0479 - acc: 0.9868 - val_loss: 0.0244 - val_acc: 0.9955\n",
            "Epoch 2/10\n",
            "8105/8105 [==============================] - 54s 7ms/step - loss: 0.0374 - acc: 0.9904 - val_loss: 1.1840 - val_acc: 0.8011\n",
            "Epoch 3/10\n",
            "8105/8105 [==============================] - 54s 7ms/step - loss: 0.1709 - acc: 0.9508 - val_loss: 0.1229 - val_acc: 0.9620\n",
            "Epoch 4/10\n",
            "8105/8105 [==============================] - 54s 7ms/step - loss: 0.0487 - acc: 0.9869 - val_loss: 0.0636 - val_acc: 0.9866\n",
            "Epoch 5/10\n",
            "8105/8105 [==============================] - 54s 7ms/step - loss: 0.0354 - acc: 0.9915 - val_loss: 0.0667 - val_acc: 0.9866\n",
            "Epoch 6/10\n",
            "8105/8105 [==============================] - 54s 7ms/step - loss: 0.0238 - acc: 0.9940 - val_loss: 0.1082 - val_acc: 0.9721\n",
            "Epoch 7/10\n",
            "8105/8105 [==============================] - 54s 7ms/step - loss: 0.0245 - acc: 0.9925 - val_loss: 0.0532 - val_acc: 0.9922\n",
            "Epoch 8/10\n",
            "8105/8105 [==============================] - 54s 7ms/step - loss: 0.0069 - acc: 0.9988 - val_loss: 0.0478 - val_acc: 0.9933\n",
            "Epoch 9/10\n",
            "8105/8105 [==============================] - 54s 7ms/step - loss: 0.0056 - acc: 0.9991 - val_loss: 0.0471 - val_acc: 0.9922\n",
            "Epoch 10/10\n",
            "8105/8105 [==============================] - 54s 7ms/step - loss: 0.0051 - acc: 0.9989 - val_loss: 0.0460 - val_acc: 0.9922\n",
            "Training on fold 8/10...\n",
            "Train on 8107 samples, validate on 893 samples\n",
            "Epoch 1/10\n",
            "8107/8107 [==============================] - 56s 7ms/step - loss: 0.0123 - acc: 0.9972 - val_loss: 0.0070 - val_acc: 0.9978\n",
            "Epoch 2/10\n",
            "8107/8107 [==============================] - 54s 7ms/step - loss: 0.0083 - acc: 0.9984 - val_loss: 0.0041 - val_acc: 0.9989\n",
            "Epoch 3/10\n",
            "8107/8107 [==============================] - 53s 7ms/step - loss: 0.0068 - acc: 0.9986 - val_loss: 0.0033 - val_acc: 1.0000\n",
            "Epoch 4/10\n",
            "8107/8107 [==============================] - 54s 7ms/step - loss: 0.0093 - acc: 0.9974 - val_loss: 0.0056 - val_acc: 0.9989\n",
            "Epoch 5/10\n",
            "8107/8107 [==============================] - 53s 7ms/step - loss: 0.0068 - acc: 0.9984 - val_loss: 0.0026 - val_acc: 0.9989\n",
            "Epoch 6/10\n",
            "8107/8107 [==============================] - 53s 7ms/step - loss: 0.0058 - acc: 0.9986 - val_loss: 0.0052 - val_acc: 0.9989\n",
            "Epoch 7/10\n",
            "8107/8107 [==============================] - 53s 7ms/step - loss: 0.0059 - acc: 0.9981 - val_loss: 0.0054 - val_acc: 1.0000\n",
            "Epoch 8/10\n",
            "8107/8107 [==============================] - 53s 7ms/step - loss: 0.0049 - acc: 0.9986 - val_loss: 0.0036 - val_acc: 0.9978\n",
            "Epoch 9/10\n",
            "8107/8107 [==============================] - 53s 7ms/step - loss: 0.0043 - acc: 0.9989 - val_loss: 0.0026 - val_acc: 1.0000\n",
            "Epoch 10/10\n",
            "8107/8107 [==============================] - 53s 7ms/step - loss: 0.0044 - acc: 0.9985 - val_loss: 0.0025 - val_acc: 1.0000\n",
            "Training on fold 9/10...\n",
            "Train on 8111 samples, validate on 889 samples\n",
            "Epoch 1/10\n",
            "8111/8111 [==============================] - 56s 7ms/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0037 - val_acc: 0.9989\n",
            "Epoch 2/10\n",
            "8111/8111 [==============================] - 53s 7ms/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.0036 - val_acc: 0.9989\n",
            "Epoch 3/10\n",
            "8111/8111 [==============================] - 53s 7ms/step - loss: 0.0030 - acc: 0.9989 - val_loss: 0.0019 - val_acc: 0.9989\n",
            "Epoch 4/10\n",
            "8111/8111 [==============================] - 53s 7ms/step - loss: 0.0041 - acc: 0.9985 - val_loss: 0.0019 - val_acc: 0.9989\n",
            "Epoch 5/10\n",
            "8111/8111 [==============================] - 53s 7ms/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.0032 - val_acc: 0.9989\n",
            "Epoch 6/10\n",
            "8111/8111 [==============================] - 53s 7ms/step - loss: 0.0031 - acc: 0.9988 - val_loss: 0.0036 - val_acc: 0.9989\n",
            "Epoch 7/10\n",
            "8111/8111 [==============================] - 53s 7ms/step - loss: 0.0034 - acc: 0.9988 - val_loss: 0.0025 - val_acc: 0.9989\n",
            "Epoch 8/10\n",
            "8111/8111 [==============================] - 53s 7ms/step - loss: 0.0026 - acc: 0.9990 - val_loss: 0.0040 - val_acc: 0.9989\n",
            "Epoch 9/10\n",
            "8111/8111 [==============================] - 53s 7ms/step - loss: 0.0027 - acc: 0.9990 - val_loss: 0.0032 - val_acc: 0.9989\n",
            "Epoch 10/10\n",
            "8111/8111 [==============================] - 53s 7ms/step - loss: 0.0024 - acc: 0.9989 - val_loss: 0.0022 - val_acc: 0.9989\n",
            "Training on fold 10/10...\n",
            "Train on 8113 samples, validate on 887 samples\n",
            "Epoch 1/10\n",
            "8113/8113 [==============================] - 56s 7ms/step - loss: 0.0027 - acc: 0.9990 - val_loss: 0.0022 - val_acc: 0.9989\n",
            "Epoch 2/10\n",
            "8113/8113 [==============================] - 53s 7ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.0025 - val_acc: 0.9989\n",
            "Epoch 3/10\n",
            "8113/8113 [==============================] - 53s 7ms/step - loss: 0.0034 - acc: 0.9986 - val_loss: 0.0027 - val_acc: 0.9989\n",
            "Epoch 4/10\n",
            "8113/8113 [==============================] - 54s 7ms/step - loss: 0.0023 - acc: 0.9989 - val_loss: 0.0034 - val_acc: 0.9989\n",
            "Epoch 5/10\n",
            "8113/8113 [==============================] - 53s 7ms/step - loss: 0.0025 - acc: 0.9990 - val_loss: 0.0035 - val_acc: 0.9989\n",
            "Epoch 6/10\n",
            "8113/8113 [==============================] - 54s 7ms/step - loss: 0.0026 - acc: 0.9990 - val_loss: 0.0039 - val_acc: 0.9989\n",
            "Epoch 7/10\n",
            "8113/8113 [==============================] - 54s 7ms/step - loss: 0.0024 - acc: 0.9989 - val_loss: 0.0039 - val_acc: 0.9989\n",
            "Epoch 8/10\n",
            "8113/8113 [==============================] - 54s 7ms/step - loss: 0.0024 - acc: 0.9989 - val_loss: 0.0036 - val_acc: 0.9989\n",
            "Epoch 9/10\n",
            "8113/8113 [==============================] - 53s 7ms/step - loss: 0.0022 - acc: 0.9989 - val_loss: 0.0041 - val_acc: 0.9989\n",
            "Epoch 10/10\n",
            "8113/8113 [==============================] - 53s 7ms/step - loss: 0.0020 - acc: 0.9990 - val_loss: 0.0039 - val_acc: 0.9989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "asKiw33FJV1k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f313b607-3385-498f-a0fe-942c06c4b6d2"
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "DATA_PATH = \"/content/drive/My Drive/kaggle_hw4\""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Oov7ltvRhWtl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model.save(os.path.join(DATA_PATH, 'vgg_crossval.h5'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uWEDk1Pm8lLS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2e4cb7d0-dbd5-4d7f-d1a7-438846355669"
      },
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "print(DATA_PATH)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/drive/My Drive/kaggle_hw4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UY_bl54cirHI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dc027921-a956-4e09-9d0d-9b6845d72fdb"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "saved_model = keras.models.load_model(os.path.join(DATA_PATH , 'vgg_crossval.h5'))\n",
        "score = saved_model.evaluate(x = vgg_validation_data, y= validation_targets)\n",
        "print(\"eval from save model\", score)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 3s 3ms/step\n",
            "eval from save model [3.039840970993042, 0.659]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_PeEOL2f9DcC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "28bf6544-235d-48eb-e493-33272a83d8aa"
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x = vgg_validation_data, y= validation_targets)\n",
        "print(\"eval from current trained model\", score)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 3s 3ms/step\n",
            "eval from current trained model [3.039840970993042, 0.659]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lBn7y01qQthl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load pickle from the test data preprocessed\n",
        "with open(os.path.join(DATA_PATH, \"vgg_test_data_preproc.pickle\"), 'rb') as jar:\n",
        "  vgg_test_data = pickle.load(jar)  \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PiAYdmoA9U5X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_predicted = saved_model.predict(vgg_test_data)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EvYaZ_ymjAUn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# pickle the results\n",
        "with open(os.path.join(DATA_PATH, \"test_predicted_cross_val.pickle\"), 'wb') as jar:\n",
        "    pickle.dump(test_predicted, jar, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}