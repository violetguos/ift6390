{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Part: Neural Network Implementation & Experiments\n",
    "\n",
    "Team:\n",
    "* Jonathan Bhimani-Burrows (20178260)\n",
    "* Arlie Coles (20121051)\n",
    "* Yue (Violet) Guo (20120727)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Fashion MNIST data:\n",
    "Note: keep your file structures like this for reading input data without\n",
    "using ```import os``` for path change!\n",
    "```\n",
    "./Homework 3\n",
    "├── 3_practical_part.ipynb\n",
    "├── circles.txt\n",
    "├── data\n",
    "│   ├── fashion\n",
    "│   │   ├── t10k-images-idx3-ubyte.gz\n",
    "│   │   ├── t10k-labels-idx1-ubyte.gz\n",
    "│   │   ├── train-images-idx3-ubyte.gz\n",
    "│   │   └── train-labels-idx1-ubyte.gz\n",
    "│   └── mnist\n",
    "│       └── README.md\n",
    "├── hw3\n",
    "│   └── d3english.pdf\n",
    "├── overleaf_url.txt\n",
    "└── utils\n",
    "    ├── __init__.py\n",
    "    ├── __pycache__\n",
    "    │   ├── __init__.cpython-36.pyc\n",
    "    │   └── mnist_reader.cpython-36.pyc\n",
    "    ├── argparser.py\n",
    "    ├── helper.py\n",
    "    └── mnist_reader.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.mnist_reader as mnist_reader\n",
    "import numpy as np\n",
    "import math\n",
    "import copy \n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist('data/fashion', kind='t10k')\n",
    "X_valid = X_test[0:5000]\n",
    "y_valid = y_test[0:5000]\n",
    "X_test = X_test[5000:10000]\n",
    "y_test = y_test[5000:10000]\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Circles data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 2)\n",
      "[1 1 0 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "circlesData = np.loadtxt(open('circles.txt','r'))\n",
    "circlesTarget = circlesData[:,2]\n",
    "circlesData = circlesData[:,[0,1]] \n",
    "#circlesData = circlesData\n",
    "#circlesData = np.expand_dims(circlesData, axis = 1)\n",
    "#circlesData = circlesData.reshape(1100, 2, 1)\n",
    "print(circlesData.shape)\n",
    "circlesTarget = np.array([int(i) for i in circlesTarget])\n",
    "print(circlesTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class loadData:\n",
    "    def __init__(self, data_type = 'circles'):\n",
    "        self.addOnes = False\n",
    "        self.data_path = '/data/'\n",
    "    \n",
    "    def convertTarget(self, targetValues):\n",
    "        # Convert to one-hot encoding\n",
    "        numClasses = np.max(targetValues) + 1\n",
    "        return np.eye(numClasses)[targetValues]\n",
    "    \n",
    "\n",
    "    def loadNumData(self, data, target):\n",
    "        # Split into train/validation/test\n",
    "        \n",
    "        np.random.seed(6390)\n",
    "        randIndices = np.random.permutation(data.shape[0])\n",
    "        data, target = data[randIndices], target[randIndices]\n",
    "        \n",
    "        div1 = int(math.floor(0.8 * data.shape[0]))\n",
    "        div2 = int(math.floor(0.9 * data.shape[0]))\n",
    "        trainData, trainTarget = data[:div1], target[:div1]\n",
    "        validData, validTarget = data[div1:div2], target[div1:div2]\n",
    "        testData, testTarget = data[div2:], target[div2:]\n",
    "    \n",
    "        # Get one hot encoding\n",
    "        trainTarget = self.convertTarget(trainTarget)\n",
    "        validTarget = self.convertTarget(validTarget)\n",
    "        testTarget = self.convertTarget(testTarget)\n",
    "        \n",
    "        return trainData, trainTarget, validData, validTarget, testData, testTarget\n",
    "\n",
    "dataLoader = loadData()\n",
    " \n",
    "trainData, trainTarget, validData, validTarget, testData, testTarget = dataLoader.loadNumData(circlesData, circlesTarget)\n",
    "\n",
    "\n",
    "#y_train = np.expand_dims(y_train, axis = 1)\n",
    "y_train =  np.array([int(i) for i in y_train])\n",
    "y_train = loadData().convertTarget(y_train)\n",
    "y_test =  np.array([int(i) for i in y_test])\n",
    "y_test = loadData().convertTarget(y_test)\n",
    "y_valid =  np.array([int(i) for i in y_valid])\n",
    "y_valid = loadData().convertTarget(y_valid)\n",
    "\n",
    "print(y_valid.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "\n",
    "> As a beginning, start with an implementation that computes the gradients for a single example, and check that the gradient is correct using the finite difference method described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSampler(object):\n",
    "    '''\n",
    "    randomly sample batches without replacement.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, data, targets, batch_size):\n",
    "        self.num_points = data.shape[0]\n",
    "        self.features = data.shape[1]\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(self.num_points)\n",
    "\n",
    "    def get_batch(self, K = None):\n",
    "        '''\n",
    "        Get a random batch without replacement \n",
    "        '''\n",
    "        \n",
    "        if not K:\n",
    "            indices = np.random.choice(self.indices, self.batch_size, replace=False)\n",
    "        else:\n",
    "            indices = np.arange(K)\n",
    "        X_batch = np.take(self.data, indices, 0)\n",
    "        y_batch = self.targets[indices]\n",
    "        return X_batch, y_batch\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our own activation functions\n",
    "\n",
    "def relu(pre_activation):\n",
    "    '''\n",
    "    preactivation is a vector\n",
    "    '''\n",
    "    relu_output = np.zeros(pre_activation.shape)\n",
    "    relu_flat = relu_output.flatten()\n",
    "    for i, neuron in enumerate(pre_activation.flatten()):\n",
    "        if neuron > 0:\n",
    "            relu_flat[i] = neuron\n",
    "    relu_output = relu_flat.reshape(pre_activation.shape)\n",
    "    return relu_output\n",
    "\n",
    "def softmax_single(pre_activation):\n",
    "    '''\n",
    "    Numerically stable because subtracting the max value makes bit overflow impossible,\n",
    "    we will only have non-positive values in the vector\n",
    "    '''\n",
    "    exps = np.exp(pre_activation - np.max(pre_activation))\n",
    "    return exps / np.sum(exps)\n",
    "\n",
    "def softmax_multiple(pre_activation):\n",
    "    '''\n",
    "    Numerically stable because subtracting the max value makes bit overflow impossible,\n",
    "    we will only have non-positive values in the vector\n",
    "    '''\n",
    "    exps = np.exp(pre_activation - np.max(pre_activation, axis = 0))\n",
    "    return exps / np.sum(exps, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_fixed = np.array([[ 0.20960823 , 0.13663559], [ 0.38623373, -0.32807251] ,[-0.63849439 , 0.0131154 ],\n",
    "                     [ 0.5142807 ,  0.0595152 ], [-0.31075243 , 0.52335846]])\n",
    "w2_fixed = np.array( [[ 0.06159592, -0.10424877,  0.23591191 , 0.06177611 , 0.42799154],\n",
    "                      [ 0.40780062,  0.0759027  , 0.09284926, -0.14837115 ,  0.16844463]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classErr(target, predicted):\n",
    "    '''\n",
    "    not class dependent\n",
    "    target must NOT be in one hot\n",
    "    '''\n",
    "    cnt = 0\n",
    "    #print(\"in class Err\")\n",
    "    #print(\"target \\n\", target.shape[0])\n",
    "    #print(\"predicted \\n\", predicted.shape[0])\n",
    "    #print(\"target range \\n\", np.max(target))\n",
    "    #print(\"predicted range \\n\", np.max(predicted))\n",
    "    for i in range(target.shape[0]):\n",
    "        if target[i] != predicted [i]:\n",
    "            cnt +=1\n",
    "    return float(cnt) / target.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralNet():\n",
    "    def __init__(self, d, dh, m, n, eta=3e-4, regularize=None, fixed=False):\n",
    "        self.inputDim = d #inputDim\n",
    "        self.hiddenDim = dh #hiddenDim\n",
    "        self.outputDim = m #outputDim\n",
    "        self.regularize = regularize # lambda value\n",
    "        self.learningRate = eta\n",
    "        self.numData = n\n",
    "        self.batchErrorGradients = []\n",
    "        self.regularize = regularize\n",
    "        #may use xavier init - maybe explore this later.\n",
    "        \n",
    "        # Initial weights and biases\n",
    "        if fixed:\n",
    "            self.W_1 = w1_fixed\n",
    "            self.W_2 = w2_fixed\n",
    "\n",
    "\n",
    "        else:\n",
    "            self.W_1 = np.random.uniform(-1/np.sqrt(d), 1/np.sqrt(d), dh*d).reshape(dh, d)\n",
    "            self.W_2 = np.random.uniform(-1/np.sqrt(dh), 1/np.sqrt(dh), dh*m).reshape(m, dh) \n",
    "        \n",
    "        self.b_1 = np.zeros(dh).reshape(dh,)\n",
    "        self.b_2 = np.zeros(m).reshape(m,)\n",
    "\n",
    "\n",
    "    def fprop(self, batchData, mode='matrix'):\n",
    "        '''\n",
    "        a switch to work for both matrix and loop\n",
    "        '''\n",
    "        if mode == 'matrix':\n",
    "            #print('self.b1', self.b_1.shape)\n",
    "            #print('self.W_1', self.W_1.shape)\n",
    "            #print('batchData.T', batchData.T.shape)\n",
    "            stack_b1 = np.array([self.b_1,] * self.numData).T\n",
    "            #print('stack_b1', stack_b1.shape)\n",
    "            self.h_a = np.dot(self.W_1, batchData.T) + stack_b1\n",
    "        elif mode == 'loop':\n",
    "            self.h_a = np.dot(self.W_1, batchData.T) + self.b_1\n",
    "            \n",
    "\n",
    "        self.h_s = relu(self.h_a)\n",
    "        \n",
    "        if mode == 'matrix':\n",
    "            stack_b2 = np.array([self.b_2,] * self.numData).T\n",
    "            self.o_a = np.dot(self.W_2, self.h_s) + stack_b2\n",
    "        elif mode == 'loop':\n",
    "            self.o_a = np.dot(self.W_2, self.h_s) + self.b_2\n",
    "        \n",
    "        if batchData.shape[0] == 1:\n",
    "            print('using single softmax')\n",
    "            self.o_s = softmax_single(self.o_a)\n",
    "        else:\n",
    "            self.o_s = softmax_multiple(self.o_a)\n",
    "        \n",
    "        if mode == 'loop':\n",
    "            self.prediction = np.argmax(self.o_s,axis = 0)\n",
    "        elif mode == 'matrix':\n",
    "            self.prediction = np.argmax(self.o_s,axis = 0)\n",
    "        \n",
    "    def errorRate(self, y, mode='matrix'):\n",
    "        '''\n",
    "        negative log\n",
    "        -logO_s(x)\n",
    "        HAD the indexing problem for matrix mode\n",
    "        '''        \n",
    "        \n",
    "        if mode == 'loop':\n",
    "            negLog = -self.o_a[np.argmax(y)] + np.log(np.sum(np.exp(self.o_a), axis=0))\n",
    "            \n",
    "        elif mode == 'matrix':\n",
    "            negLog = []\n",
    "            for i in range(y.shape[1]):\n",
    "                error_at_point = -self.o_a[np.argmax(y[:,i])][i] + np.log(np.sum(np.exp(self.o_a), axis=0))[i]\n",
    "                negLog.append(error_at_point)\n",
    "            negLog = np.array(negLog)\n",
    "            negLog = np.mean(negLog)\n",
    "\n",
    "        return negLog\n",
    "          \n",
    "    def bpropLoop(self, batchData, batchTarget):\n",
    "        '''\n",
    "        dimensions: \n",
    "        o_s: m x1\n",
    "        grad_oa : m x 1\n",
    "        hs: dh x 1\n",
    "        grad_w2: m x dh\n",
    "        grad_oa: m x n\n",
    "        grad_b2: m x n\n",
    "        grad_oa: m x n\n",
    "        W(2): m x dh\n",
    "        grad_hs: dh x n\n",
    "        grad_oa: m x n\n",
    "        grad_ha: dh x n\n",
    "        x : n x d\n",
    "        grad_W1: dh x d\n",
    "        grad_ha: dh x n\n",
    "        grad_b1: dh x n\n",
    "        '''\n",
    "\n",
    "        self.grad_oa = self.o_s - batchTarget\n",
    "        self.grad_W2 = np.outer(self.grad_oa, self.h_s.T)\n",
    "        self.grad_b2 = self.grad_oa\n",
    "        self.grad_hs = np.dot(self.W_2.T , self.grad_oa)\n",
    "        h_a_stack = np.where(self.h_a > 0, 1, 0)\n",
    "        self.grad_ha = np.multiply(self.grad_hs, h_a_stack)\n",
    "        self.grad_W1 = np.outer(self.grad_ha, batchData)\n",
    "        self.grad_b1 = self.grad_ha\n",
    "        \n",
    "        \n",
    "    def bprop_matrix(self, batchData, batchTarget):\n",
    "        '''\n",
    "        backprop using matrix only\n",
    "        '''\n",
    "        \n",
    "        self.grad_oa = self.o_s - batchTarget\n",
    "        self.grad_W2 = np.matmul(self.grad_oa, self.h_s.T)/batchData.shape[0] #!\n",
    "        self.grad_b2 = np.sum(self.grad_oa, axis=1)/batchData.shape[0] #!\n",
    "        self.grad_hs = np.matmul(self.W_2.T, self.grad_oa)\n",
    "        self.grad_ha = np.multiply(self.grad_hs, np.where(self.h_a > 0, 1.0, 0.0))\n",
    "        self.grad_W1 = np.matmul(self.grad_ha, batchData)/batchData.shape[0] #!\n",
    "        self.grad_b1 = np.sum(self.grad_ha, axis=1)/batchData.shape[0] #!\n",
    "        \n",
    "    def bprop(self, batchData, batchTarget, mode='matrix'):\n",
    "        '''\n",
    "        batchTarget already in one-hot format\n",
    "        \n",
    "        NOT working for a single point\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        #batch target must be m by n\n",
    "        self.grad_oa = self.o_s - batchTarget\n",
    "        i = 0\n",
    "        self.grad_W2 = [np.outer(self.grad_oa[:,i], self.h_s[:,i].T) for i in range(batchData.shape[0])]\n",
    "        self.grad_b2 = self.grad_oa \n",
    "        self.grad_hs = np.dot(self.W_2.T , self.grad_oa)\n",
    "        # Check this (dim mismatch maybe)\n",
    "        h_a_stack = np.where(self.h_a > 0, 1, 0)\n",
    "        self.grad_ha = np.multiply(self.grad_hs, h_a_stack)\n",
    "        #self.grad_W1 = [np.outer(self.grad_ha[:,i], batchData[i]) for i in range(self.numData)]\n",
    "        self.grad_W1 = [np.outer(self.grad_ha[:,i], batchData[i]) for i in range(batchData.shape[0])]\n",
    "        # temporary hack for grad_W\n",
    "        self.grad_b1 = self.grad_ha\n",
    "\n",
    "        \n",
    "        if mode == 'matrix':\n",
    "            '''\n",
    "            must avg, \n",
    "            1 pt would return a list of MAT/np array, not a NP array\n",
    "            '''\n",
    "            self.grad_W2 = np.average(np.array(self.grad_W2), axis=0)\n",
    "            self.grad_b2 = np.average(np.array(self.grad_b2), axis=1)\n",
    "            \n",
    "            self.grad_W1 = np.average(np.array(self.grad_W1), axis=0)\n",
    "            self.grad_b1 = np.average(np.array(self.grad_b1), axis=1)\n",
    "\n",
    "\n",
    "        \n",
    "    def updateParams(self):\n",
    "        if self.regularize:\n",
    "            self.W_1 -= (self.regularize[0] * np.sign(self.W_1) + 2 * self.regularize[1] * self.W_1) * self.learningRate\n",
    "            self.W_2 -= (self.regularize[2] * np.sign(self.W_2) + 2 * self.regularize[3] * self.W_2) * self.learningRate\n",
    "        \n",
    "        \n",
    "        self.W_1 -= self.grad_W1 * self.learningRate\n",
    "        self.W_2 -= self.grad_W2 * self.learningRate\n",
    "        self.b_1 -= self.grad_b1 * self.learningRate\n",
    "        self.b_2 -= self.grad_b2 * self.learningRate\n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    def gradDescentLoop(self, batchData, batchTarget, K):\n",
    "        # Call each example in the data (over the minibatches) in a loop\n",
    "        grad_W2, grad_b2, grad_W1, grad_b1 = [], [], [], []\n",
    "        predBatch = []\n",
    "        for i in range(K):\n",
    "            self.fprop(batchData[i], mode='loop') #batchTarget[:,i]\n",
    "            self.bpropLoop(batchData[i],np.array(batchTarget[:,i]))\n",
    "            predBatch.append(self.prediction)\n",
    "            grad_W2.append(self.grad_W2)\n",
    "            grad_b2.append(self.grad_b2)\n",
    "            grad_W1.append(self.grad_W1)\n",
    "            grad_b1.append(self.grad_b1)\n",
    "        self.grad_W2 = np.mean(np.array(grad_W2), axis=0) #! array\n",
    "        self.grad_b2 = np.mean(np.array(grad_b2), axis=0) \n",
    "        self.grad_W1 = np.mean(np.array(grad_W1), axis=0) #! array\n",
    "        self.grad_b1 = np.mean(np.array(grad_b1), axis=0)\n",
    "        \n",
    "        # Update params\n",
    "        #self.updateParams()\n",
    "    \n",
    "    def fpropLoop(self, batchData, K):\n",
    "        '''\n",
    "        unlike the above def gradDescentLoop(self, batchData, batchTarget, K)\n",
    "        this function only runs batchData (this is usually in test phase)\n",
    "        through the forward prop, without calculating any gradient update rule.\n",
    "        \n",
    "        Use to get predictions\n",
    "        \n",
    "        batchData: more like test/val data\n",
    "        K: ALWAYS == batchData.shape[0]\n",
    "        \n",
    "        '''\n",
    "        predBatch = []\n",
    "        for i in range(K):\n",
    "            self.fprop(batchData[i], mode='loop') #batchTarget[:,i]\n",
    "            predBatch.append(self.prediction)\n",
    "        self.predBatch = np.array(predBatch)    \n",
    "        \n",
    "    def gradDescentMat(self, batchData, batchTarget):\n",
    "        # Feed the entire data matrix in as input\n",
    "        self.fprop(batchData)\n",
    "        self.bprop_matrix(batchData, batchTarget)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "#### Question:\n",
    "> Display  the  gradients  for  both  methods (direct computation and finite difference) for a small network (e.g. $d = 2$ and $d_{h} = 2$) with random weights and for a single example.\n",
    "\n",
    "#### Answer:\n",
    "See notebook `3_practical_part_loop.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "\n",
    "#### Question:\n",
    "> Add a hyperparameter for the minibatch size $K$ to allow computing the gradients on a minibatch of $K$ examples (in a matrix), by looping over the $K$ examples (this is a small addition to your previous code).\n",
    "\n",
    "#### Answer:\n",
    "See `class neuralNet():` `    def bprop_matrix(self, batchData, batchTarget):` in the cells above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4\n",
    "#### Question:\n",
    "> Display the gradients for both methods (direct computation and finite difference) for a small network (e.g. $d = 2$ and $d_{h} = 2$) with random weights and for a minibatch with 10 examples (you can use examples from both classes from the two circles dataset).\n",
    "#### Answer:\n",
    "See notebook `3_practical_part_loop.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5\n",
    "\n",
    "#### Question:\n",
    "> Train your neural network using gradient descent on the two circles dataset. Plot the decision regions for several different values of the hyperparameters (weight decay, number of hidden units, early stopping) so as to illustrate their effect on the capacity of the model.\n",
    "\n",
    "#### Answer:\n",
    "See notebook `3_practical_part_loop.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6\n",
    "\n",
    "Our training function(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_error(nn, epoch, train, valid, test):\n",
    "    '''\n",
    "    calculattes error in matrix mode\n",
    "    '''\n",
    "    # Train\n",
    "    nn.numData = train[0].shape[0]\n",
    "\n",
    "    nn.fprop(train[0], mode='matrix')\n",
    "    training_loss = nn.errorRate(train[1].T, mode='matrix')\n",
    "    training_err = classErr(np.argmax(train[1], axis = 1), nn.prediction)\n",
    "    \n",
    "    # Valid\n",
    "    nn.numData = valid[0].shape[0]\n",
    "    nn.fprop(valid[0], mode='matrix') \n",
    "\n",
    "    valid_loss = nn.errorRate(valid[1].T, mode='matrix')\n",
    "    valid_err = classErr(np.argmax(valid[1], axis  =1 ), nn.prediction)\n",
    "    \n",
    "    # Test\n",
    "    nn.numData = test[0].shape[0]\n",
    "\n",
    "    nn.fprop(test[0], mode='matrix') \n",
    "    test_loss = nn.errorRate(test[1].T, mode='matrix')\n",
    "    test_err = classErr(np.argmax(test[1], axis = 1), nn.prediction)\n",
    "    \n",
    "    # Write to log file\n",
    "    with open('errors.txt', 'a+') as fp:\n",
    "        line = '{},{},{},{},{},{},{}\\n'.format(epoch, training_loss, training_err, \n",
    "                                             valid_loss, valid_err, test_loss, test_err)\n",
    "        fp.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(nn, data, target,  K, num_epoch, fixed = False): \n",
    "    '''\n",
    "    train minibtaches over num_epoch epochs (in a loop)\n",
    "    also does prediction and error calcualation\n",
    "    '''\n",
    "    # Get minibatch\n",
    "    batchSampler = BatchSampler(data, target, K)\n",
    "    numBatch = data.shape[0] // K \n",
    "    print(\"num batch in train loop \", numBatch)\n",
    "    # training loop\n",
    "    for n in range(num_epoch):\n",
    "        # Do descent and update params - this is one epoch\n",
    "        for i in range(numBatch):\n",
    "            if fixed:\n",
    "                batchData, batchTarget = batchSampler.get_batch(K)\n",
    "\n",
    "            elif not fixed:\n",
    "                batchData, batchTarget = batchSampler.get_batch()\n",
    "            #difference: another loop here\n",
    "            nn.gradDescentLoop(batchData, batchTarget.T, K)\n",
    "            nn.updateParams()\n",
    "        if n % 100 == 0:\n",
    "            nn.fpropLoop(data, data.shape[0]) \n",
    "            print(\"Cross-entropy loss at the end of epoch {}: {}\".format(n, nn.errorRate(target.T, mode = 'loop')))\n",
    "            print(\"classification error at the end of epoch {}: {}\".format(n,\n",
    "                                                    classErr(np.argmax(target, axis = 1), nn.predBatch)))        \n",
    "    \n",
    "    # finalized weights, need to fprop and get the error rate \n",
    "    # a for loop inside the prop for each elem\n",
    "    nn.fpropLoop(data, data.shape[0]) \n",
    "    print(\"End of train loop process.\")\n",
    "\n",
    "\n",
    "def train_matrix(nn, data, target, K, num_epoch, fixed=False, valid=None, test=None):\n",
    "    # Get minibatch\n",
    "    batchSampler = BatchSampler(data, target, K)\n",
    "    numBatch = data.shape[0] // K \n",
    "    \n",
    "    print(\"number of batch in train matrix\", numBatch)\n",
    "    for n in range(num_epoch):\n",
    "        for i in range(numBatch):\n",
    "            # Do descent and update params - this is one epoch\n",
    "\n",
    "            if fixed:\n",
    "                batchData, batchTarget = batchSampler.get_batch(K)\n",
    "            elif not fixed:\n",
    "                batchData, batchTarget = batchSampler.get_batch()\n",
    "            nn.numData = K\n",
    "            nn.gradDescentMat(batchData, batchTarget.T)\n",
    "            \n",
    "            nn.updateParams()\n",
    "        if n % 100 == 0:\n",
    "            print(':)')\n",
    "            #nn.fprop(batchData, mode = 'matrix') \n",
    "            #pred = np.argmax(nn.o_s, axis = 0)\n",
    "            #print(\"Cross-entropy loss at the end of epoch {}: {}\".format(n, nn.errorRate(batchTarget.T, mode = 'matrix')))\n",
    "            #print(\"classification error at the end of epoch {}: {}\".format(n,\n",
    "            #                                        classErr(np.argmax(batchTarget, axis = 1), pred ))) \n",
    "        if valid:\n",
    "            nn.numData = valid[0].shape[0]\n",
    "            show_error(nn, n, [data, target], valid, test)\n",
    "    print(\"End of train matrix process.\")\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to plot the decision boundary and decision regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(nn, X, y):\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h betweethem\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole gid\n",
    "    \n",
    "    newData =np.c_[xx.ravel(), yy.ravel()]\n",
    "    \n",
    "    nn.fpropLoop(newData, newData.shape[0])\n",
    "    Z = nn.predBatch\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral)\n",
    "    plt.show()\n",
    "    \n",
    "def plotDecision(nn, data):\n",
    "    nn.fpropLoop(data, data.shape[0])\n",
    "    plt.scatter(data[:,0], data[:,1], c = nn.predBatch)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We vary the number of hidden units:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6\n",
    "\n",
    "> As a second step, copy your existing implementation to modify it to a new implementation that will use matrix calculus (instead of a loop) on batches of size $K$ to improve efficiency. **Take the matrix expressions in numpy derived in the first part, and adapt them for a minibatch of size $K$. Show in your report what you have modified (describe the former and new expressions with the shapes of each matrix).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the forward prop method, these lines in the matrix form:\n",
    "```\n",
    "stack_b1 = np.array([self.b_1,] * self.numData).T # dh x n\n",
    "self.h_a = np.dot(self.W_1, batchData.T) + stack_b1 # dh x n\n",
    "self.h_s = relu(self.h_a) # dh x n\n",
    "stack_b2 = np.array([self.b_2,] * self.numData).T # m x n\n",
    "self.o_a = np.dot(self.W_2, self.h_s) + stack_b2 # m x n\n",
    "self.o_s = softmax_single(self.o_a) # m x n   \n",
    "```\n",
    "changed from these lines in the loop form:\n",
    "```\n",
    "self.h_a = np.dot(self.W_1, batchData.T) + self.b_1 # dh x 1\n",
    "self.h_s = relu(self.h_a) # dh x 1\n",
    "self.o_a = np.dot(self.W_2, self.h_s) + self.b_2 # m x 1\n",
    "self.o_s = softmax_multiple(self.o_a) # m x 1\n",
    "```\n",
    "\n",
    "\n",
    "In the backprop method, these lines in the matrix form:\n",
    "```\n",
    "self.grad_W2 = np.matmul(self.grad_oa, self.h_s.T)/batchData.shape[0] # m x dh\n",
    "self.grad_b2 = np.sum(self.grad_oa, axis=1)/batchData.shape[0] # m x n\n",
    "self.grad_hs = np.matmul(self.W_2.T, self.grad_oa) # dh x n\n",
    "self.grad_W1 = np.matmul(self.grad_ha, batchData)/batchData.shape[0] # dh x d\n",
    "self.grad_b1 = np.sum(self.grad_ha, axis=1)/batchData.shape[0] # dh x n\n",
    "```\n",
    "changed from these lines in the loop form:\n",
    "```\n",
    "self.grad_W2 = np.outer(self.grad_oa, self.h_s.T) # m x dh\n",
    "self.grad_b2 = self.grad_oa # m x 1\n",
    "self.grad_hs = np.dot(self.W_2.T, self.grad_oa) # dh x 1\n",
    "self.grad_W1 = np.outer(self.grad_ha, batchData) # dh x d\n",
    "self.grad_b1 = self.grad_ha # dh x 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 7\n",
    "\n",
    "> Compare both implementations (with a loop and with matrix calculus) to check that they both give the same values for the gradients on the parameters, first for $K = 1$, then for $K = 10$. Display the gradients for both methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num batch in train loop  1\n",
      "Cross-entropy loss at the end of epoch 0: 0.712802180806613\n",
      "classification error at the end of epoch 0: 1.0\n",
      "End of train loop process.\n",
      "Gradients for K = 1 for loop method\n",
      "grad_W1:\n",
      " [[ 0.14607752 -0.09866548]\n",
      " [ 0.07507537 -0.05070833]\n",
      " [ 0.          0.        ]\n",
      " [-0.08953771  0.06047666]\n",
      " [ 0.          0.        ]]\n",
      "grad_b1:\n",
      " [ 0.17627682  0.09059606  0.         -0.10804827  0.        ]\n",
      "grad_W2:\n",
      " [[-0.04918903 -0.2565906   0.         -0.20054434  0.        ]\n",
      " [ 0.04918903  0.2565906   0.          0.20054434  0.        ]]\n",
      "grad_b2:\n",
      " [-0.50985489  0.50985489]\n",
      "\n",
      "number of batch in train matrix 1\n",
      "using single softmax\n",
      ":)\n",
      "End of train matrix process.\n",
      "Gradients for K = 1 for matrix method\n",
      "grad_W1:\n",
      " [[ 0.14605376 -0.09864943]\n",
      " [ 0.07500453 -0.05066048]\n",
      " [-0.          0.        ]\n",
      " [-0.08958163  0.06050633]\n",
      " [-0.          0.        ]]\n",
      "grad_b1:\n",
      " [ 0.17624815  0.09051057  0.         -0.10810126  0.        ]\n",
      "grad_W2:\n",
      " [[-0.04915827 -0.25655692 -0.         -0.20054537 -0.        ]\n",
      " [ 0.04915827  0.25655692  0.          0.20054537  0.        ]]\n",
      "grad_b2:\n",
      " [-0.50981549  0.50981549]\n"
     ]
    }
   ],
   "source": [
    "# Loop with K = 1\n",
    "K = 1\n",
    "test_net = neuralNet(2, 5, 2, K, fixed = True)\n",
    "\n",
    "num_epoch = 1\n",
    "train_loop(test_net, trainData[0:1], trainTarget[0:1], K, num_epoch, fixed = True)\n",
    "\n",
    "print('Gradients for K = 1 for loop method')\n",
    "print('grad_W1:\\n', test_net.grad_W1)\n",
    "print('grad_b1:\\n', test_net.grad_b1)\n",
    "print('grad_W2:\\n', test_net.grad_W2)\n",
    "print('grad_b2:\\n', test_net.grad_b2)\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "# Matrix with K = 1\n",
    "K = 1\n",
    "test_net = None\n",
    "test_net = neuralNet(2, 5, 2, K, fixed = True)\n",
    "train_matrix(test_net, trainData[0:1], trainTarget[0:1], K, num_epoch, fixed = True)\n",
    "\n",
    "print('Gradients for K = 1 for matrix method')\n",
    "print('grad_W1:\\n', test_net.grad_W1)\n",
    "print('grad_b1:\\n', test_net.grad_b1)\n",
    "print('grad_W2:\\n', test_net.grad_W2)\n",
    "print('grad_b2:\\n', test_net.grad_b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the gradients for K =1 are approximately equal for both methods\n",
    "\n",
    "|  loop method K = 1 |  matrix method K = 1 |\n",
    "|---|---|\n",
    "| `grad_W1:` | `grad_W1:` |\n",
    "| `[[ 0.14607752 -0.09866548]` | `[[ 0.14605376 -0.09864943]` |\n",
    "| `[ 0.07507537 -0.05070833]` | `[ 0.07500453 -0.05066048]` |\n",
    "| `[ 0.          0.        ]` |  `[-0.          0.        ]` |\n",
    "| `[-0.08953771  0.06047666]` |  `[-0.08958163  0.06050633]` |\n",
    "| `[ 0.          0.        ]]` |`[-0.          0.        ]]`  | \n",
    "| grad_b1:  |  grad_b1: |\n",
    "| `[ 0.17627682  0.09059606  0.         -0.10804827  0.        ]`  |  ` [ 0.17624815  0.09051057  0.        -0.10810126  0.        ]` |\n",
    "|grad_W2: | grad_W2: |\n",
    "| `[[-0.04918903 -0.2565906   0.         -0.20054434  0.        ]` | `[[-0.04918903 -0.2565906   0.         -0.20054434  0.        ]`|\n",
    "| `[ 0.04918903  0.2565906   0.          0.20054434  0.        ]]`|` [ 0.04915827  0.25655692  0.          0.20054537  0.        ]]`|\n",
    "|grad_b2:|grad_b2:|\n",
    "|`[-0.50985489  0.50985489]`| `[-0.50981549  0.50981549]`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num batch in train loop  1\n",
      "Cross-entropy loss at the end of epoch 0: 0.7047291558063856\n",
      "classification error at the end of epoch 0: 0.9\n",
      "End of train loop process.\n",
      "Gradients for K = 10 for matrix method\n",
      "\n",
      "grad_W1:\n",
      " [[ 0.04570254 -0.01350108]\n",
      " [ 0.02237507 -0.04267427]\n",
      " [-0.00217299  0.0160907 ]\n",
      " [-0.03009897  0.01902831]\n",
      " [-0.00901618  0.00338832]]\n",
      "grad_b1:\n",
      " [ 0.05271274  0.06332756 -0.00540759 -0.04328806  0.01649891]\n",
      "grad_W2:\n",
      " [[-0.02226261 -0.12752366  0.01117303 -0.06771283  0.01763218]\n",
      " [ 0.02226261  0.12752366 -0.01117303  0.06771283 -0.01763218]]\n",
      "grad_b2:\n",
      " [-0.29342348  0.29342348]\n",
      "\n",
      "number of batch in train matrix 1\n",
      ":)\n",
      "End of train matrix process.\n",
      "Gradients for K = 10 with matrix method\n",
      "\n",
      "grad_W1:\n",
      " [[ 0.04569944 -0.01350008]\n",
      " [ 0.02236473 -0.04265515]\n",
      " [-0.00217285  0.01608975]\n",
      " [-0.03010388  0.01903147]\n",
      " [-0.0090157   0.0033881 ]]\n",
      "grad_b1:\n",
      " [ 0.05270916  0.06329898 -0.00540728 -0.04329521  0.01649807]\n",
      "grad_W2:\n",
      " [[-0.02226003 -0.12751693  0.0111723  -0.06771269  0.01763176]\n",
      " [ 0.02226003  0.12751693 -0.0111723   0.06771269 -0.01763176]]\n",
      "grad_b2:\n",
      " [-0.29341701  0.29341701]\n"
     ]
    }
   ],
   "source": [
    "# Loop with K = 10\n",
    "K = 10\n",
    "test_net = neuralNet(2, 5, 2, K, fixed=True)\n",
    "train_loop(test_net, trainData[0:10], trainTarget[0:10], K, 1, fixed = True)\n",
    "\n",
    "print('Gradients for K = 10 for matrix method\\n')\n",
    "print('grad_W1:\\n', test_net.grad_W1)\n",
    "print('grad_b1:\\n', test_net.grad_b1)\n",
    "print('grad_W2:\\n', test_net.grad_W2)\n",
    "print('grad_b2:\\n', test_net.grad_b2)\n",
    "\n",
    "print()\n",
    "# Matrix with K = 10\n",
    "K = 10\n",
    "test_net = neuralNet(2, 5, 2, K, fixed=True)\n",
    "train_matrix(test_net, trainData[0:10], trainTarget[0:10], K, 1, fixed = True)\n",
    "\n",
    "print('Gradients for K = 10 with matrix method\\n')\n",
    "print('grad_W1:\\n', test_net.grad_W1)\n",
    "print('grad_b1:\\n', test_net.grad_b1)\n",
    "print('grad_W2:\\n', test_net.grad_W2)\n",
    "print('grad_b2:\\n', test_net.grad_b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  loop method K = 10 |   matrix method K = 10 |\n",
    "|---|---|\n",
    "|grad_W1:|grad_W1:|\n",
    "|` [[ 0.04570254 -0.01350108]`|`[[ 0.04569944 -0.01350008]`|\n",
    "|` [ 0.02237507 -0.04267427]`|`[ 0.02236473 -0.04265515]`|\n",
    "|`[-0.00217299  0.0160907 ]`|`[-0.00217285  0.01608975`|\n",
    "|`[-0.03009897  0.01902831]`|`[-0.03010388  0.01903147]`|\n",
    "|`[-0.00901618  0.00338832]]`|`[-0.0090157   0.0033881 ]]`|\n",
    "|grad_b1:|grad_b1:|\n",
    "|`[ 0.05271274  0.06332756 -0.00540759 -0.04328806  0.01649891]`|` [ 0.05270916  0.06329898 -0.00540728 -0.04329521  0.01649807]`|\n",
    "|grad_W2:|grad_W2:|\n",
    "|` [[-0.02226261 -0.12752366  0.01117303 -0.06771283  0.01763218]`|`[[-0.02226003 -0.12751693  0.0111723  -0.06771269  0.01763176]`|\n",
    "|`[ 0.02226261  0.12752366 -0.01117303  0.06771283 -0.01763218]]`|`[ 0.02226003  0.12751693 -0.0111723   0.06771269 -0.01763176]]`|\n",
    "|grad_b2:|grad_b2:|\n",
    "|`[-0.29342348  0.29342348]`|`[-0.29341701  0.29341701]`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 8\n",
    "#### Question:\n",
    "> Time how long an epoch takes on Fashion MNIST (1 epoch = 1 full traversal through the whole training set) for $K = 100$ for both versions (loop over a minibatch and matrix caluclus).\n",
    "\n",
    "#### Explanation:\n",
    "> we have fixed number of hidden units = 15 for both methods.\n",
    "```\n",
    "Cross-entropy loss at the end of epoch 0: 2.5725120825683683\n",
    "classification error at the end of epoch 0: 0.6430666666666667\n",
    "End of train loop process.\n",
    "--- 1 epoch on MNIST (loop method): 17.253093957901 seconds ---\n",
    "number of batch in train matrix 600\n",
    ":)\n",
    "End of train matrix process.\n",
    "--- 1 epoch on MNIST (matrix method): 7.790565729141235 seconds ---\n",
    "```\n",
    "\n",
    "> for hidden units = 200\n",
    "```\n",
    "num batch in train loop  600\n",
    "Cross-entropy loss at the end of epoch 0: 29.81888086769734\n",
    "classification error at the end of epoch 0: 0.20175\n",
    "End of train loop process.\n",
    "--- 1 epoch on MNIST (loop method): 135.12508082389832 seconds ---\n",
    "number of batch in train matrix 600\n",
    ":)\n",
    "End of train matrix process.\n",
    "--- 1 epoch on MNIST (matrix method): 11.82770299911499 seconds ---\n",
    "```\n",
    "\n",
    "\n",
    "We remark that computation time increase by the same order of magnitude with magnitude of epoches in loop method due to the nature of nested loops, while the Matrix method increases only 4 seconds when number of neurons increase by one order of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num batch in train loop  600\n",
      "Cross-entropy loss at the end of epoch 0: 29.81888086769734\n",
      "classification error at the end of epoch 0: 0.20175\n",
      "End of train loop process.\n",
      "--- 1 epoch on MNIST (loop method): 135.12508082389832 seconds ---\n",
      "number of batch in train matrix 600\n",
      ":)\n",
      "End of train matrix process.\n",
      "--- 1 epoch on MNIST (matrix method): 11.82770299911499 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# train the Fashion MINIST\n",
    "# K is batch size\n",
    "K = 100\n",
    "num_epochs = 1\n",
    "\n",
    "# Loop method\n",
    "fmNet = neuralNet(X_train.shape[1], 200, 10, K)\n",
    "start_time = time.time()\n",
    "train_loop(fmNet, X_train, y_train, K, num_epochs)\n",
    "print(\"--- 1 epoch on MNIST (loop method): {} seconds ---\".format(time.time() - start_time))\n",
    "\n",
    "# Matrix method\n",
    "fmNet = neuralNet(X_train.shape[1], 200, 10, K)\n",
    "start_time = time.time()\n",
    "train_matrix(fmNet, X_train, y_train, K, num_epochs)\n",
    "print(\"--- 1 epoch on MNIST (matrix method): {} seconds ---\".format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 9\n",
    "\n",
    "> Adapt your code to compute the error (proportion of misclassified examples) on the training set as well as the total loss on the training set during each epoch of the training procedure, and at the end of each epoch, it computes the error and average loss on the validation set and the test set. Display the 6 corresponding figures (error and average loss on train/valid/test), and write them in a log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      ":)\n",
      "End of train matrix process.\n"
     ]
    }
   ],
   "source": [
    "# Test to see if logging/plotting works (very simple)\n",
    "train_data = X_train#[:10000]\n",
    "train_target = y_train#[:10000]\n",
    "valid_data = X_valid#[:100]\n",
    "valid_target = y_valid#[:100]\n",
    "test_data = X_test#[:100]\n",
    "test_target = y_test#[:100]\n",
    "print(train_data.shape)\n",
    "K = 200\n",
    "num_epochs = 60\n",
    "plot_test = neuralNet(train_data.shape[1], 200, 10, K)\n",
    "#train_matrix(plot_test, X_train, y_train, K, num_epochs, valid=[X_valid, y_valid], test=[X_test, y_test])\n",
    "train_matrix(plot_test, train_data, train_target, K, num_epochs, \n",
    "             valid=[valid_data, valid_target], test=[test_data, test_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning curves\n",
    "def plot_learning_curves(log_file):\n",
    "    with open(log_file, 'r') as fp:\n",
    "        info = fp.readlines()\n",
    "        \n",
    "    epochs = np.arange(len(info))\n",
    "    \n",
    "    training_loss, valid_loss, test_loss = [], [], []\n",
    "    training_err, valid_err, test_err = [], [], []\n",
    "    \n",
    "    for line in info:\n",
    "        split_line = line.split(',')\n",
    "        training_loss.append(float(split_line[1]))\n",
    "        training_err.append(float(split_line[2]))\n",
    "        valid_loss.append(float(split_line[3]))\n",
    "        valid_err.append(float(split_line[4]))\n",
    "        test_loss.append(float(split_line[5]))\n",
    "        test_err.append(float(split_line[6]))\n",
    "    \n",
    "    # Plot\n",
    "    plt.title(\"average cross entropy loss\")\n",
    "    plt.plot(epochs, training_loss, c='blue', linestyle='solid', label = 'train loss')\n",
    "    plt.plot(epochs, valid_loss, c='green', linestyle='solid', label = 'valid loss')\n",
    "    plt.plot(epochs, test_loss, c='orange', linestyle='solid', label = 'test loss')\n",
    "    plt.xlabel('number of epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    plt.title(\"classification errors\")\n",
    "    plt.plot(epochs, training_err, c='blue', linestyle='dashed', label = 'train error')\n",
    "    plt.plot(epochs, valid_err, c='green', linestyle='dashed', label = 'valid error')\n",
    "    plt.plot(epochs, test_err, c='orange', linestyle='dashed', label = 'test error')\n",
    "    plt.xlabel('number of epoch')\n",
    "    plt.ylabel('error')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 10\n",
    "\n",
    "> Train your network on the Fashion MNIST dataset. Plot the training/valid/test curves (error and loss as a function of the epoch number, corresponding to what you wrote in a file in the last question). Add to your report the curves obtained using your best hyperparameters, i.e. for which you obtained your best error on the validations et. We suggest 2 plots: the first one will plot the error rate (train/valid/test with different colors, show which color in a legend) and the other one for the averaged loss (on train/valid/test). You should be able to get less than 20% test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curves('errors.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
